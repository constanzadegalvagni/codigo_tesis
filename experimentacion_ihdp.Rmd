---
title: "Experimentación de superficies A y B"
author: "Constanza de Galvagni"
date: '2025'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning = FALSE}
library(Metrics)
library(dbarts)
library(tibble)
library(stochtree)
library(grf)
library(coda)

seed = 1729
```

En este archivo se replica la experimentación realizada por Hill en su artículo de 2011 para evaluar la performance de BART en la predicción del CATE y el ATE para distintas superficies de respuesta basadas en el dataset IHDP.
A su vez, se extiende este análisis a los modelos BCF y CF.

Se replican las métricas explicadas en la sección 5.3 de la tesis sobre `niters` superficies de cada tipo.
Para cada iteración, se escriben secuencialmente los resultados sobre un archivo .csv para cada tipo de superficie.



Leemos los datos usados por Hill con los que construyó las simulaciones

```{r}
load('data/sim.data')
niters = 500
```

Simulamos que los datos observados son sólo de niños tratados con madre blanca y clasificamos las variables

```{r}
obs <- imp1[!(imp1$treat==1 & imp1$momwhite==0),]

covars_continuas = c("bw","b.head","preterm","birth.o","nnhealth","momage")
covars_categoricas = c("sex","twin","b.marr","mom.lths","mom.hs",	"mom.scoll","cig","first","booze","drugs","work.dur","prenatal","ark","ein","har","mia","pen","tex","was")
p = length(c(covars_continuas, covars_categoricas))
all_covars <- c(covars_continuas, covars_categoricas)

#Convierto a los tipos necesarios para el input de ciertos modelos

data_obs <- obs[,c(all_covars, "treat")]
matrix_obs <- as.matrix(data_obs) #notar que matrix_obs incluye la columna de tratamiento

col_tratamiento = obs$treat
```

Estandarización

```{r}
X = obs[, all_covars]

#Estandarizamos las variables continuas
X[, covars_continuas] = as.data.frame(
  t(
    (t(X[, covars_continuas]) - unlist(lapply(X[,covars_continuas], mean)))/
      sqrt(unlist(lapply(X[,covars_continuas], stats::var)))
  )
)

#Guardamos el número de observaciones y de covariables
N = nrow(X)
dimx = ncol(X)
Xmat = as.matrix(X) #Xmat no incluye la columna de tratamiento

#Separamos X en el conjunto de entrenamiento y de testeo
set.seed(seed)

muestra <- sample(c(TRUE, FALSE), nrow(matrix_obs), replace = TRUE, prob = c(0.7,0.3))
obs_train <- matrix_obs[muestra, ]
obs_test <- matrix_obs[!muestra, ]
betaA = sample(x = c(.0,.1,.2,.3,.4), size = dimx + 1, replace = TRUE, prob = c(.5,.2,.15,.1,.05))
betaB = c(sample(c(.0,.1,.2,.3,.4),dimx+1,replace=TRUE,prob=c(.6,.1,.1,.1,.1)))

Ntrain = sum(muestra)
Ntest = N - sum(muestra)

X_train <- obs_train[, -ncol(obs_train)]
Z_train <- obs_train[, ncol(obs_train)]
X_test <- obs_test[, -ncol(obs_test)]
Z_test <- obs_test[, ncol(obs_test)]

obs_train_z_0 <- obs_train
obs_train_z_0[,"treat"] = 0
obs_train_z_1 <- obs_train
obs_train_z_1[,"treat"] = 1

obs_test_z_0 <- obs_test
obs_test_z_0[,"treat"] = 0
obs_test_z_1 <- obs_test
obs_test_z_1[,"treat"] = 1

#Hago estas matrices para tener las estimaciones de tau para BART, ya que es el único modelo que no devuelve una estimación de mismo
X_train_contrafact <- data.frame(rbind(obs_train_z_1, obs_train_z_0))
X_test_contrafact <- data.frame(rbind(obs_test_z_1, obs_test_z_0)) 
```

Creamos los dataframes en donde nos vamos a guardar los resultados obtenidos.
También creamos los csv donde vamos a ir guardando los resultados a medida que hagamos las simulaciones.

```{r}
nouts = 2
outputs = c("YA", "YB")

colnames_resultados_bart <- c("BART.error_ate", "BART.gelman", "BART.prop_effSize",
                              "BART.rmse_cate_train", "BART.rmse_cate_test",
                              "BART.coverage_cate_train", "BART.coverage_cate_test",
                              "BART.tam_medio_ic_cate_train", "BART.tam_medio_ic_cate_test",
                              "BART.tiempo(s)"
                              )

colnames_resultados_bcf <- c("BCF.error_ate", "BCF.prop_effSize", "BCF.autocorr",
                             "BCF.tam_medio_ic_cate_train", "BCF.tam_medio_ic_cate_test",
                             "BCF.rmse_cate_train", "BCF.rmse_cate_test",
                             "BCF.coverage_cate_train", "BCF.coverage_cate_test",
                             "BCF.tiempo(s)"
                             )

colnames_resultados_cf <- c("CF.error_ate", "CF.tam_medio_ic_cate_train", "CF.tam_medio_ic_cate_test",
                            "CF.rmse_cate_train", "CF.rmse_cate_test",
                            "CF.coverage_cate_train", "CF.coverage_cate_test",
                            "CF.tiempo(s)")

colnames_resultados <- c(colnames_resultados_bart, colnames_resultados_bcf, colnames_resultados_cf)

results_a <- data.frame(matrix(ncol = length(colnames_resultados), nrow = 0))
colnames(results_a) <- colnames_resultados

results_b <- results_a
```

```{r}

if (!dir.exists("resultados")) {
  dir.create("resultados")
}

write.csv(results_a,file = "resultados/results_sup_A.csv", row.names = FALSE)
write.csv(results_b, file = "resultados/results_sup_B.csv", row.names = FALSE)

superficies <- c("supA", "supB")
conjuntos   <- c("train", "test")
modelos     <- c("BART", "BCF", "CF")

if (niters == 1){
for (sup in superficies) {
  for (set in conjuntos) {
    for (mod in modelos) {
      if (sup == "supA") {
        df <- data.frame(CATE_real = numeric(0),
                         CATE_estimado = numeric(0),
                         cubre = integer(0)) 
      } else if (sup == "supB") {
        df <- data.frame(CATE_real = numeric(0),
                         CATE_estimado = numeric(0),
                         cubre = integer(0)) 
      }

            
      nombre_archivo <- paste0("resultados_sup_aleatoria/cate_", sup, "_", set, "_", mod, ".csv")
      write.table(df,
                  file = nombre_archivo,
                  sep = ",",
                  row.names = FALSE,
                  col.names = TRUE,
                  quote = FALSE)
    }
  }
}
}

```

## Simulaciones

Creamos las funciones necesarias para simular outcomes de las distintas superficies de respuesta.

### Superficie de respuesta A
$$
Y(0) \sim \mathcal{N}(X \beta_A, 1)
$$

$$
Y(1) \sim \mathcal{N}(X \beta_A + 4, 1)
$$
Donde $X$ es la matriz estandarizada de covariables y $\beta$ es un vector de coeficientes con la misma longitud que la cantidad de covariables, con valores sampleados aleatoriamente del conjunto $\{0,1,2,3,4\}$ con probabilidades $\{0.5,0.2,0.15,0.1,0.05\}$ respectivamente.

De esta manera:
```{r}
samplear_sup_A <- function(seed){
  set.seed(seed)
  #betaA = sample(x = c(.0,.1,.2,.3,.4), size = dimx + 1, replace = TRUE, prob = c(.5,.2,.15,.1,.05))
  mean_y0 = cbind(rep(1,N),Xmat) %*% betaA
  epsilon = rnorm(N,0,1)
  YA0 = mean_y0 + epsilon
  YA1 = mean_y0 + 4 + epsilon
  
  #Creamos el vector YA de respuestas observadas
  YA = YA1; YA[col_tratamiento == 0] = YA0[col_tratamiento==0]
  
  return(list(
    YA = YA,
    YA0 = YA0,
    YA1 = YA1
    ))
}
```

En este caso se está modelando una superficie lineal y paralela a los grupos tratados, en un escenario sin heterogeneidad para el CATE.

### Superficie de respuesta B
$$
Y(0) \sim \mathcal{N}(\text{exp}((X+W)\beta_B),1)
$$

$$
Y(1) \sim \mathcal{N}(X\beta_B - \omega^s_B,1)
$$
Donde $W$ es una matriz $\textit{offset}$ de la misma dimensión de X con todos los valores en 0.5, $\beta_B$ es un vector de coeficientes de regresión $\{0,0.1,0.2,0.3,0.4\}$ sampleados aleatoriamente con probabilidades $\{0.6,0.1,0.1,0.1,0.1\}$ 

Estos parámetros resultan en un ATE = 4.

```{r}
samplear_sup_B <- function(seed) {
  set.seed(seed)
  #betaB = c(sample(c(.0,.1,.2,.3,.4),dimx+1,replace=TRUE,prob=c(.6,.1,.1,.1,.1)))
  mean_yb0 = exp((cbind(rep(1,N), (Xmat+.5)) %*% betaB))
  mean_yb1 = cbind(rep(1,N),(Xmat+.5))%*%betaB

  offset = c(mean(mean_yb1-mean_yb0)) - 4
  mean_yb1 = cbind(rep(1,N), (Xmat+.5)) %*% betaB - offset
  
  epsilon <- rnorm(N, 0, 1)
  
  YB0 = mean_yb0 + epsilon
  YB1 = mean_yb1 + epsilon
  
  #Vector YB de respuestas observadas
  YB = YB1; YB[col_tratamiento==0] = YB0[col_tratamiento == 0]
  
  return(list(
    YB = YB,
    YB0 = YB0,
    YB1 = YB1
    ))
}
```


## Ajuste de modelos

#### BART
```{r}
ajustar_barts<- function(Y, n.chains, n.burn, n.samples, n.thin, seed, tipo_superficie){
  fmla <- as.formula(paste("y ~", paste(c(all_covars, "treat"), collapse = " + ")))
  df_train <- data.frame(cbind(X_train, treat = Z_train, y = Y[[1]][muestra]))
  
  y = Y[[1]]
  y0 = Y[[2]]
  y1 = Y[[3]]
  
  y_train = y[muestra]
  y_test = y[!muestra]
  
  y0_train = y0[muestra]
  y0_test = y0[!muestra]
  
  y1_train = y1[muestra]
  y1_test = y1[!muestra]
  
  tiempo_bart <- system.time({
   bart <- dbarts::bart2(formula = fmla,
                         data = df_train,
                         verbose = FALSE,
                         keepTrees = TRUE,
                         n.chains = n.chains, #5
                         n.burn = n.burn, #50
                         n.samples = n.samples #2000
                         ,n.thin=n.thin, #2
                         seed = seed
   )
  })
   
  predict_train <- data.frame(X_train_contrafact)
  predict_train$y <- c(y1_train, y0_train)
  tau_teorico_train <- y1_train - y0_train

  predict_test <- data.frame(X_test_contrafact)
  predict_test$y <- c(y1_test, y0_test)
  tau_teorico_test <- y1_test - y0_test
    
  outcomes_train_completo <- predict(bart, newdata = cbind(X_train_contrafact))
  outcomes_test_completo <- predict(bart, newdata = cbind(X_test_contrafact))
  
  outcomes_train = colMeans(outcomes_train_completo) #Promediamos las predicciones de todas las cadenas
  outcomes_test = colMeans(outcomes_test_completo)
  
  #En este caso para las predicciones de los outcomes sí combinamos las cadenas
  
  tau_train <- outcomes_train[1:Ntrain] - outcomes_train[(Ntrain+1):(2*Ntrain)] 
  tau_test <- outcomes_test[1:Ntest] - outcomes_test[(Ntest+1):(2*Ntest)]
  
  estimacion_ate = mean(c(tau_train, tau_test))
  error_ate = rmse(4, estimacion_ate)
  
  sd_tau_train <- apply(outcomes_train_completo[,1:Ntrain] - outcomes_train_completo[,(Ntrain+1):(2*Ntrain)], 2, sd)
  sd_tau_test <- apply(outcomes_test_completo[,1:Ntest] - outcomes_test_completo[,(Ntest+1):(2*Ntest)], 2, sd)
  
  total_cov_tau_train <- rep(0, Ntrain)
  tam_medio_ic_tau_train <- rep(0, Ntrain)
  for (i in 1:Ntrain){
    inf = tau_train[i] - 1.96*sd_tau_train[i]
    sup = tau_train[i] + 1.96*sd_tau_train[i]
    tam_medio_ic_tau_train[i] = sup - inf
    if(inf < tau_teorico_train[i] & sup > tau_teorico_train[i]){
      total_cov_tau_train[i] = 1
    }
  }
  cov_tau_train = mean(total_cov_tau_train)
  tam_medio_ic_tau_train = mean(tam_medio_ic_tau_train)
  
  total_cov_tau_test = rep(0, Ntest)
  tam_medio_ic_tau_test = rep(0, Ntest)
  for(i in 1:Ntest){
    inf = tau_test[i] - 1.96*sd_tau_test[i]
    sup = tau_test[i] + 1.96*sd_tau_test[i]
    tam_medio_ic_tau_test[i] = sup-inf
    if(inf < tau_teorico_test[i] & sup > tau_teorico_test[i]){
      total_cov_tau_test[i] = 1
    }
  }
  cov_tau_test = mean(total_cov_tau_test)
  tam_medio_ic_tau_test = mean(tam_medio_ic_tau_test)
  
  #Calculamos diagnóstico de Gelman y effectiveSize de las MCMCs
  #Primero necesitamos re-entrenar los mismos BART sin hacer combine_chains para no perder las cadenas
  chains = predict(bart, newdata = predict_train, combineChains = FALSE)
  
  #Los predict tienen tamaño n_chains x tam_cadenas x individuos
  #Para calcular el diagnóstico de Gelman necesitamos tener todo en formato mcmc.list

  gelman_individuos <- numeric(Ntrain)
  effSize_individuos <- numeric(Ntrain)
  
  for(j in 1:Ntrain){
    cadenas_j <- vector("list", n.chains)
    for (i in 1:n.chains){
      cadenas_j[[i]] <- mcmc(chains[i,,j])
    }
    mcmclist_j <- mcmc.list(cadenas_j)
    gelman_individuos[j] <- gelman.diag(mcmclist_j)$psrf[1]
    effSize_individuos[j] <- effectiveSize(mcmclist_j)
  }
  
  #Antes de cerrar, guardamos los datos de CATE real vs predict en el archivo correspondiente
  if (niters == 1){
  if (tipo_superficie == "A"){
    write.table(data.frame(tau_teorico_train, tau_train, total_cov_tau_train),
                file = "resultados_sup_aleatoria/cate_supA_train_BART.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
      write.table(data.frame(tau_teorico_test, tau_test, total_cov_tau_test),
                file = "resultados_sup_aleatoria/cate_supA_test_BART.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
  } else if (tipo_superficie == "B") {
    write.table(data.frame(tau_teorico_train, tau_train, total_cov_tau_train),
                file = "resultados_sup_aleatoria/cate_supB_train_BART.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
    write.table(data.frame(tau_teorico_test, tau_test, total_cov_tau_test),
                file = "resultados_sup_aleatoria/cate_supB_test_BART.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
  }
  }
  
  return(list(
    error_ate = error_ate,
    gelman = mean(gelman_individuos),
    prop_effSize = mean(effSize_individuos)/n.samples,
    rmse_cate_train = rmse(tau_teorico_train, tau_train),
    rmse_cate_test = rmse(tau_teorico_test, tau_test),
    coverage_cate_train = cov_tau_train,
    coverage_cate_test = cov_tau_test,
    tam_medio_ic_cate_train = tam_medio_ic_tau_train,
    tam_medio_ic_cate_test = tam_medio_ic_tau_test,
    tiempo_bart = tiempo_bart["elapsed"]
    ))
}
```

#### BCF
```{r}
ajustar_bcf <- function(Y, num_gfr, num_burnin, num_mcmc, prognostic_trees, treatment_trees, seed, tipo_superficie){
  y = Y[[1]]
  y0 = Y[[2]]
  y1 = Y[[3]]
  
  tiempo_bcf <- system.time({
  BCF <- stochtree::bcf(
    X_train = X_train,
    Z_train = Z_train,
    y_train = y[muestra],
    X_test = X_test,
    Z_test = Z_test,
      # Parámetros de muestreo
    num_gfr = num_gfr,                   #5
    num_burnin = num_burnin,              #400
    num_mcmc = num_mcmc,                #400
    # Parámetros específicos para los bosques
    general_params = list(
      verbose = FALSE, # NO Mostrar progreso
      random_seed = seed
    ),
    prognostic_forest_params = list(
      num_trees = prognostic_trees              #20
    ),
    treatment_effect_forest_params = list(
      num_trees = treatment_trees              #5
    )
  )
  })

  taus_train = BCF$tau_hat_train
  taus_test = BCF$tau_hat_test
  
  tau_teorico_train = y1[muestra] - y0[muestra]
  tau_teorico_test = y1[!muestra] - y0[!muestra]
  # dim(BCF$tau_hat_train) = nrow(X_train) x num_mcmc
  
  markovChain_train <- BCF$y_hat_train #tamaño individuos x num_mcmc
  markovChain_test <- BCF$y_hat_test
  
  effSize_individuos_train <- numeric(Ntrain)
  autocorr_individuos_train <- numeric(Ntrain)
  
  for(i in 1:Ntrain){
    effSize_individuos_train[i] = effectiveSize(mcmc(markovChain_train[i,]))
    autocorr_individuos_train[i] = acf(markovChain_train[i,], lag.max = 30, plot=FALSE)$acf[2]
  }
  
  est_tau_train <- apply(taus_train, 1, mean)
  est_tau_test <- apply(taus_test, 1, mean)
  sd_tau_train <- apply(taus_train, 1, sd)
  sd_tau_test <- apply(taus_test, 1, sd)
  
  ci_tau_train <- matrix(0, nrow = Ntrain, ncol = 4)
  ci_tau_test <- matrix(0, nrow = Ntest, ncol = 4)
  
  for (i in 1:Ntrain){
    ci_tau_train[i, 1:2] <- c(est_tau_train[i] - 1.96*sd_tau_train[i],
                         est_tau_train[i] + 1.96*sd_tau_train[i])
    ci_tau_train[i,3] <- (ci_tau_train[i,1] < tau_teorico_train[i] & ci_tau_train[i,2] > tau_teorico_train[i]) * 1
    ci_tau_train[i,4] <- ci_tau_train[i,2] - ci_tau_train[i,1]
  }
  
  for (i in 1:Ntest){
    ci_tau_test[i, 1:2] <- c(est_tau_test[i] - 1.96*sd_tau_test[i],
                        est_tau_test[i] + 1.96*sd_tau_test[i])
    ci_tau_test[i,3] <- (ci_tau_test[i,1] < tau_teorico_test[i] & ci_tau_test[i,2] > tau_teorico_test[i]) * 1
    ci_tau_test[i,4] <- ci_tau_test[i,2] - ci_tau_test[i,1]
  }
  
  coverage_cate_train <- mean(ci_tau_train[,3])
  coverage_cate_test <- mean(ci_tau_test[,3])
  tam_medio_ic_train <- mean(ci_tau_train[,4])
  tam_medio_ic_test <- mean(ci_tau_test[,4])
  
  est_ate = mean(c(taus_train, taus_test))
  
    #Antes de cerrar, guardamos los datos de CATE real vs predict en el archivo correspondiente
  if (niters == 1){
  if (tipo_superficie == "A"){
    write.table(data.frame(tau_teorico_train, est_tau_train, ci_tau_train[,3]),
                file = "resultados_sup_aleatoria/cate_supA_train_BCF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
      write.table(data.frame(tau_teorico_test, est_tau_test, ci_tau_test[,3]),
                file = "resultados_sup_aleatoria/cate_supA_test_BCF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
  } else if (tipo_superficie == "B") {
    write.table(data.frame(tau_teorico_train, est_tau_train, ci_tau_train[,3]),
                file = "resultados_sup_aleatoria/cate_supB_train_BCF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
    write.table(data.frame(tau_teorico_test, est_tau_test, ci_tau_test[,3]),
                file = "resultados_sup_aleatoria/cate_supB_test_BCF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
  }
  }
  
  
  return(list(
    error_ate = rmse(4, est_ate),
    prop_effsize = mean(effSize_individuos_train)/num_mcmc,
    autocorr = mean(autocorr_individuos_train),
    tam_medio_ic_train = tam_medio_ic_train,
    tam_medio_ic_test = tam_medio_ic_test,
    rmse_tau_train = rmse(tau_teorico_train, est_tau_train),
    rmse_tau_test = rmse(tau_teorico_test, est_tau_test),
    coverage_cate_train = coverage_cate_train,
    coverage_cate_test = coverage_cate_test,
    tiempo_bcf = tiempo_bcf["elapsed"]
  ))
}
```

#### CF
```{r}
ajustar_cf <- function(Y, num_trees, sample_fraction, honesty.fraction, mtry, min.node.size, alpha, seed, tipo_superficie){
  y = Y[[1]]
  y0 = Y[[2]]
  y1 = Y[[3]]

  y_train <- y[muestra]
  y_test <- y[!muestra]
  
  tau_teorico_train <- y1[muestra] - y0[muestra]
  tau_teorico_test <- y1[!muestra] - y0[!muestra]
  
  y_forest <- grf::regression_forest(X = X_train, Y=y_train)
  y_hat <- y_forest$predictions
  
  z_forest <- grf::regression_forest(X = X_train, Y = Z_train)
  z_hat <- z_forest$predictions
  
  tiempo_cf <- system.time({
  CF <- grf::causal_forest(X = X_train,
                           W = Z_train,
                           Y = y_train,
                           Y.hat = y_hat,
                           W.hat = z_hat,
                           num.trees = num_trees, #5000
                           sample.fraction = sample_fraction, #0.3
                           honesty.fraction = honesty.fraction, #0.5
                           mtry = mtry, #12
                           min.node.size = min.node.size, #1
                           alpha = alpha, #0.005
                           seed = seed
                           )
  })

  #Devolvemos las estimaciones del tau para train y test para comparar con el tau original
  pred_cf_train <- predict(CF, newdata=X_train, estimate.variance = TRUE)
  pred_cf_test <- predict(CF, newdata = X_test, estimate.variance = TRUE)

  tau_cf_train = pred_cf_train$predictions
  sd_cf_train = sqrt(pred_cf_train$variance.estimates)
  tau_cf_test = pred_cf_test$predictions
  sd_cf_test = sqrt(pred_cf_test$variance.estimates)
  
  ci_tau_train <- matrix(nrow = Ntrain, ncol = 4)
  ci_tau_test <- matrix(nrow = Ntest, ncol = 4)
  
  for (i in 1:Ntrain){
    ci_tau_train[i,1:2] <- c(tau_cf_train[i] - 1.96*sd_cf_train[i],
                         tau_cf_train[i] + 1.96*sd_cf_train[i])
    ci_tau_train[i,3] <- (ci_tau_train[i,1] < tau_teorico_train[i] & ci_tau_train[i,2] > tau_teorico_train[i])*1
    ci_tau_train[i,4] <- ci_tau_train[i,2] - ci_tau_train[i,1]
  }
  
  for (i in 1:Ntest){
    ci_tau_test[i,1:2] <- c(tau_cf_test[i] - 1.96*sd_cf_test[i],
                        tau_cf_test[i] + 1.96*sd_cf_test[i])
    ci_tau_test[i,3] <- (ci_tau_test[i,1] < tau_teorico_test[i] & ci_tau_test[i,2] > tau_teorico_test[i])*1
    ci_tau_test[i,4] <- ci_tau_test[i,2] - ci_tau_test[i,1]
  }
  
  coverage_cate_train <- mean(ci_tau_train[,3])
  coverage_cate_test <- mean(ci_tau_test[,3])
  tam_medio_ic_train <- mean(ci_tau_train[,4])
  tam_medio_ic_test <- mean(ci_tau_test[,4])
  
  ate_est = mean(c(tau_cf_train, tau_cf_test))
  
  #Escribimos cate real y estimado
  if (niters == 1){
  if (tipo_superficie == "A"){
    write.table(data.frame(tau_teorico_train, tau_cf_train, ci_tau_train[,3]),
                file = "resultados_sup_aleatoria/cate_supA_train_CF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
      write.table(data.frame(tau_teorico_test, tau_cf_test, ci_tau_test[,3]),
                file = "resultados_sup_aleatoria/cate_supA_test_CF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
  } else if (tipo_superficie == "B") {
    write.table(data.frame(tau_teorico_train, tau_cf_train, ci_tau_train[,3]),
                file = "resultados_sup_aleatoria/cate_supB_train_CF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
    write.table(data.frame(tau_teorico_test, tau_cf_test, ci_tau_test[,3]),
                file = "resultados_sup_aleatoria/cate_supB_test_CF.csv",
                sep = ",",
                row.names = FALSE,
                col.names = FALSE,
                quote = FALSE,
                append = TRUE)
  }
  }
  

  return(list(
    error_ate = rmse(4, ate_est),
    tam_medio_ic_train = tam_medio_ic_train,
    tam_medio_ic_test = tam_medio_ic_test,
    rmse_tau_train = rmse(tau_teorico_train, tau_cf_train),
    rmse_tau_test = rmse(tau_teorico_test, tau_cf_test),
    coverage_cate_train = coverage_cate_train,
    coverage_cate_test = coverage_cate_test,
    tiempo_cf = tiempo_cf["elapsed"]
    )
  )
}
```

## Evaluación de resultados

```{r warning=FALSE}
evaluar_modelos <- function(seed){
  YA <- samplear_sup_A(seed)
  YB <- samplear_sup_B(seed)
  set.seed(seed)
  #Para cada superficie vamos corriendo los modelos con los hiperparámetros óptimos y guardando los resultados
  
  est_bart_YA <- ajustar_barts(YA, 5, 50, 2000, 2, seed, "A")
  est_bcf_YA <- ajustar_bcf(YA, 5, 400, 400, 20, 5, seed, "A")
  est_cf_YA <- ajustar_cf(YA, 5000, 0.3, 0.5, 12, 1, 0.005, seed, "A")
  
  est_bart_YB <- ajustar_barts(YB, 5, 50, 2000, 2, seed, "B")
  est_bcf_YB <- ajustar_bcf(YB, 5, 400, 400, 20, 5, seed, "B")
  est_cf_YB <- ajustar_cf(YB, 5000, 0.3, 0.5, 12, 1, 0.005, seed, "B")
  
  #escribimos los datos en los csv
  fila_resultado_A <- as.data.frame(as.list(c(est_bart_YA, est_bcf_YA, est_cf_YA)))
  fila_resultado_B <- as.data.frame(as.list(c(est_bart_YB, est_bcf_YB, est_cf_YB)))


  write.table(fila_resultado_A, file = "resultados/results_sup_A.csv",
            sep = ",", row.names = FALSE, col.names = !file.exists("resultados/results_sup_A.csv"),
            append = TRUE)

  write.table(fila_resultado_B, file = "resultados/results_sup_B.csv",
            sep = ",", row.names = FALSE, col.names = !file.exists("resultados/results_sup_B.csv"),
            append = TRUE)
}

seeds <- numeric(niters)
for(i in 1:niters){
    #Para cada semilla se genera una sup.de rta.
    if(i<=(niters/2)){seeds[i] <- (565 + i*5)}
    if(i>(niters/2)){seeds[i] <- (7565 + i*5)}
}

```

Por último, creamos la función que corre todo en paralelo, para mejor eficiencia.

Este chunk está desactivado para que no se corra durante el knit.

```{r warning=FALSE}
library(future.apply)
plan(multisession, workers = parallel::detectCores()-1)

resultados <- future_lapply(seeds, function(semilla){
  library(here)
  set.seed(semilla)
  evaluar_modelos(semilla)
}, future.seed = TRUE)
```

